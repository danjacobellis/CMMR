{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1569f7a3-3ea5-4003-8997-62a3971dd8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "from datasets import load_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as nnf\n",
    "from torchvision.transforms import ToPILImage\n",
    "from torchvision import transforms\n",
    "from torchmetrics.classification import MulticlassJaccardIndex\n",
    "import numpy as np\n",
    "from transformers import AutoModelForImageClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d84cb093-e1fe-4b05-bc32-8cf4e37f5516",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "868eeb367ebf4c6193dc654dac87c95e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/65 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0176f3bd4cb041a1ba7d0c13bcf5a3ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/65 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ade20k_dino = load_dataset(\"danjacobellis/ade20k_dino\",split='validation').with_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c977a2e4-82bf-4613-955f-c0ba7e4d2652",
   "metadata": {},
   "outputs": [],
   "source": [
    "ade20k = load_dataset(\"scene_parse_150\",split='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c5f3424-bab3-425b-b0fa-46a8e7c114eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = AutoModelForImageClassification.from_pretrained('facebook/dinov2-giant')\n",
    "# model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee793336-b7c0-4ca0-a07b-5cadffba40f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/server/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "/home/server/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)\n",
      "  warnings.warn(\"xFormers is available (SwiGLU)\")\n",
      "/home/server/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)\n",
      "  warnings.warn(\"xFormers is available (Attention)\")\n",
      "/home/server/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)\n",
      "  warnings.warn(\"xFormers is available (Block)\")\n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('facebookresearch/dinov2', 'dinov2_vitg14').to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "737ffac6-4878-4115-b39f-6d466c8f5055",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearSegmentationHead(nn.Module):\n",
    "    def __init__(self, in_channels=1536, num_classes=150):\n",
    "        super(LinearSegmentationHead, self).__init__()\n",
    "        self.conv_seg = nn.Conv2d(in_channels, num_classes, kernel_size=1)\n",
    "        # self.bn = nn.BatchNorm2d(in_channels,track_running_stats=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = self.bn(x)\n",
    "        x = self.conv_seg(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "f7dd914d-fc39-406a-a005-42ddc0163105",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"dinov2_vitg14_ade20k_linear_head.pth\")\n",
    "new_state_dict = {key.replace(\"decode_head.\", \"\"): value for key, value in checkpoint['state_dict'].items()}\n",
    "new_state_dict.pop('bn.weight', None)\n",
    "new_state_dict.pop('bn.bias', None)\n",
    "new_state_dict.pop('bn.running_var', None)\n",
    "new_state_dict.pop('bn.running_mean', None)\n",
    "new_state_dict.pop('bn.num_batches_tracked', None)\n",
    "head = LinearSegmentationHead()\n",
    "head.load_state_dict(new_state_dict)\n",
    "head = head.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "5d432687-6746-4654-a6c3-633e21acb926",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iou = []\n",
    "for sample in ade20k:\n",
    "    img = sample['image'].resize((1344,1344))\n",
    "    ground_truth = sample['annotation']\n",
    "    while ground_truth.width > 1000:\n",
    "        ground_truth = ground_truth.resize((ground_truth.width//2,ground_truth.height//2),PIL.Image.Resampling.NEAREST)\n",
    "    x = transforms.ToTensor()(img).unsqueeze(0).to(\"cuda\")\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        # y = model.dinov2.forward(x)[0]\n",
    "        y = model.forward_features(x)\n",
    "        \n",
    "        # cls_token = y[:, 0].detach()\n",
    "        # patch_tokens = y[:, 1:].detach()\n",
    "        cls_token = y['x_norm_clstoken']\n",
    "        patch_tokens = y['x_norm_patchtokens']\n",
    "        \n",
    "        patch_tokens = patch_tokens.reshape((1,96,96,1536)).permute((0,3,1,2))\n",
    "        patch_tokens = nnf.interpolate(patch_tokens,\n",
    "                                       size=(ground_truth.height,ground_truth.width),\n",
    "                                       mode='bilinear'\n",
    "                                      )\n",
    "        logits = head(patch_tokens)\n",
    "        predicted = ToPILImage()(logits[0].argmax(dim=0).to(torch.uint8))\n",
    "        # predicted = predicted.resize((ground_truth.width,ground_truth.height),resample=PIL.Image.Resampling.BILINEAR)\n",
    "    \n",
    "        x1 = transforms.PILToTensor()(ground_truth) \n",
    "        x2 = transforms.PILToTensor()(predicted)\n",
    "        x1 = x1-1\n",
    "\n",
    "        iou.append(\n",
    "            MulticlassJaccardIndex(num_classes=151,average='micro',ignore_index=255)\n",
    "            (x1,x2).item()\n",
    "        )\n",
    "        if len(iou)>10:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "2bf40173-9cff-4c94-bcdd-bfb6a116e9d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5033409432931379"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(iou)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
