{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1569f7a3-3ea5-4003-8997-62a3971dd8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "from datasets import load_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as nnf\n",
    "from torchvision.transforms import ToPILImage\n",
    "from torchvision import transforms\n",
    "from torchmetrics.classification import MulticlassJaccardIndex\n",
    "import numpy as np\n",
    "from transformers import AutoModelForImageClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d84cb093-e1fe-4b05-bc32-8cf4e37f5516",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f301d3a73ae94549aa145dd7b14f032e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/65 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c8fd531ed1d403987140f076ea68d3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/65 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ade20k_dino = load_dataset(\"danjacobellis/ade20k_dino\",split='validation').with_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c977a2e4-82bf-4613-955f-c0ba7e4d2652",
   "metadata": {},
   "outputs": [],
   "source": [
    "ade20k = load_dataset(\"scene_parse_150\",split='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0c5f3424-bab3-425b-b0fa-46a8e7c114eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForImageClassification.from_pretrained('facebook/dinov2-giant-imagenet1k-1-layer')\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "737ffac6-4878-4115-b39f-6d466c8f5055",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearSegmentationHead(nn.Module):\n",
    "    def __init__(self, in_channels=1536, num_classes=150):\n",
    "        super(LinearSegmentationHead, self).__init__()\n",
    "        self.conv_seg = nn.Conv2d(in_channels, num_classes, kernel_size=1)\n",
    "        self.bn = nn.BatchNorm2d(in_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.bn(x)\n",
    "        x = self.conv_seg(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f7dd914d-fc39-406a-a005-42ddc0163105",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"dinov2_vitg14_ade20k_linear_head.pth\")\n",
    "new_state_dict = {key.replace(\"decode_head.\", \"\"): value for key, value in checkpoint['state_dict'].items()}\n",
    "head = LinearSegmentationHead()\n",
    "head.load_state_dict(new_state_dict)\n",
    "head = head.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d432687-6746-4654-a6c3-633e21acb926",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iou = []\n",
    "for sample in ade20k:\n",
    "    img = sample['image'].resize((224,224))\n",
    "    ground_truth = sample['annotation']\n",
    "    x = transforms.ToTensor()(img).unsqueeze(0).to(\"cuda\")\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        y = model.dinov2.forward(x)[0]\n",
    "        cls_token = y[:, 0].detach()\n",
    "        patch_tokens = y[:, 1:].detach()\n",
    "        patch_tokens = patch_tokens.reshape((1,16,16,1536)).permute((0,3,1,2))\n",
    "        patch_tokens = nnf.interpolate(patch_tokens,\n",
    "                                       size=(ground_truth.height,ground_truth.width),\n",
    "                                       mode='bicubic',\n",
    "                                       align_corners=True\n",
    "                                      )\n",
    "        logits = head(patch_tokens)\n",
    "        predicted = ToPILImage()(logits[0].argmax(dim=0).to(torch.uint8))\n",
    "    \n",
    "        x1 = transforms.PILToTensor()(ground_truth) \n",
    "        x2 = transforms.PILToTensor()(predicted)\n",
    "        x1 = x1-1\n",
    "\n",
    "        iou.append(\n",
    "            MulticlassJaccardIndex(num_classes=151,average='micro',ignore_index=255)\n",
    "            (x1,x2).item()\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
