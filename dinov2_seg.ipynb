{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1569f7a3-3ea5-4003-8997-62a3971dd8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "from datasets import load_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as nnf\n",
    "from torchvision.transforms import ToPILImage\n",
    "from torchvision import transforms\n",
    "from torchmetrics.classification import MulticlassJaccardIndex\n",
    "import numpy as np\n",
    "from transformers import AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c977a2e4-82bf-4613-955f-c0ba7e4d2652",
   "metadata": {},
   "outputs": [],
   "source": [
    "ade20k = load_dataset(\"scene_parse_150\",split='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c5f3424-bab3-425b-b0fa-46a8e7c114eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModel.from_pretrained('facebook/dinov2-giant')\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "737ffac6-4878-4115-b39f-6d466c8f5055",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearSegmentationHead(nn.Module):\n",
    "    def __init__(self, in_channels=1536, num_classes=150):\n",
    "        super(LinearSegmentationHead, self).__init__()\n",
    "        self.conv_seg = nn.Conv2d(in_channels, num_classes, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_seg(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7dd914d-fc39-406a-a005-42ddc0163105",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"dinov2_vitg14_ade20k_linear_head.pth\")\n",
    "new_state_dict = {key.replace(\"decode_head.\", \"\"): value for key, value in checkpoint['state_dict'].items()}\n",
    "new_state_dict.pop('bn.weight', None)\n",
    "new_state_dict.pop('bn.bias', None)\n",
    "new_state_dict.pop('bn.running_var', None)\n",
    "new_state_dict.pop('bn.running_mean', None)\n",
    "new_state_dict.pop('bn.num_batches_tracked', None)\n",
    "head = LinearSegmentationHead()\n",
    "head.load_state_dict(new_state_dict)\n",
    "head = head.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d432687-6746-4654-a6c3-633e21acb926",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 39s, sys: 814 ms, total: 5min 40s\n",
      "Wall time: 4min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "iou = []\n",
    "for i_sample,sample in enumerate(ade20k):\n",
    "    img = sample['image'].resize((448,252))\n",
    "    ground_truth = sample['annotation']\n",
    "    while ground_truth.width > 1000:\n",
    "        ground_truth = ground_truth.resize((ground_truth.width//2,ground_truth.height//2),PIL.Image.Resampling.NEAREST)\n",
    "    x = transforms.ToTensor()(img).unsqueeze(0).to(\"cuda\")\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        y = model.forward(x)[0]\n",
    "        cls_token = y[:, 0]\n",
    "        patch_tokens = y[:, 1:]\n",
    "        patch_tokens = patch_tokens.reshape((1,18,32,1536)).permute((0,3,1,2))\n",
    "        patch_tokens = nnf.interpolate(patch_tokens,\n",
    "                                       size=(ground_truth.height,ground_truth.width),\n",
    "                                       mode='bilinear')\n",
    "        logits = head(patch_tokens)\n",
    "        predicted = ToPILImage()(logits[0].argmax(dim=0).to(torch.uint8))\n",
    "        \n",
    "        x1 = transforms.PILToTensor()(ground_truth) \n",
    "        x2 = transforms.PILToTensor()(predicted)\n",
    "        x1 = x1-1\n",
    "\n",
    "        iou.append(\n",
    "            MulticlassJaccardIndex(num_classes=151,average='micro',ignore_index=255)\n",
    "            (x1,x2).item()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89c81934-4a1c-4b07-a906-93589ff3e77f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4219338969966702"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 448x252\n",
    "np.mean(iou)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
